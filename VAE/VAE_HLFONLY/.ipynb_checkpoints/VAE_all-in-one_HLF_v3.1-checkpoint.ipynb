{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VampPrior\n",
    "\n",
    "- Tried with 10 hidden dim -> not converged\n",
    "- Tried to add allLepMass and hidden from 4 to 5 -> Eff improve but reco is a shit\n",
    "- If remove VampEff decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import sys, scipy\n",
    "from scipy.stats import chi2, poisson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/08\n"
     ]
    }
   ],
   "source": [
    "import ROOT as rt\n",
    "import root_numpy as rtnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olmo/programs/root-6.10.08/lib/ROOT.py:318: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return _orig_ihook( name, *args, **kwds )\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers as KL\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import keras\n",
    "print keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlf_features = ['HT', 'MET', 'DPhiMETLep', 'MT', 'nJets', \n",
    "                'bJets', 'allJetMass', 'LepPt', 'LepEta', \n",
    "                'LepIsoCh', 'LepIsoGamma', 'LepIsoNeu', 'LepCharge', \n",
    "                'LepIsEle', 'nMu', 'allMuMass', 'allMuPt', 'nEle', \n",
    "                'allEleMass', 'allElePt', 'nChHad', 'nNeuHad', 'nPhoton']\n",
    "\n",
    "active_hlf_features = ['HT', 'MET', 'allJetMass',\n",
    "                       'allMuPt','allElePt','allEleMass', 'allMuMass',\n",
    "                       'LepPt', 'LepIsoCh', 'LepIsoGamma', 'LepIsoNeu',\n",
    "                       \n",
    "                       'LepEta', 'DPhiMETLep',\n",
    "                       \n",
    "                       'MT',\n",
    "                       \n",
    "                       'nMu', 'nJets', 'bJets', 'nEle', \n",
    "                       \n",
    "                       'LepCharge','LepIsEle', \n",
    "                       \n",
    "                       'nChHad', 'nNeuHad', 'nPhoton']\n",
    "\n",
    "Nf_lognorm = 11\n",
    "Nf_gauss = 2\n",
    "Nf_Pgauss = 1\n",
    "Nf_PDgauss = 4\n",
    "Nf_binomial = 2\n",
    "Nf_poisson = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated HLF:\n",
      "\tHT\n",
      "\tMET\n",
      "\tallJetMass\n",
      "\tallMuPt\n",
      "\tallElePt\n",
      "\tallEleMass\n",
      "\tallMuMass\n",
      "\tLepPt\n",
      "\tLepIsoCh\n",
      "\tLepIsoGamma\n",
      "\tLepIsoNeu\n",
      "\tLepEta\n",
      "\tDPhiMETLep\n",
      "\tMT\n",
      "\tnMu\n",
      "\tnJets\n",
      "\tbJets\n",
      "\tnEle\n",
      "\tLepCharge\n",
      "\tLepIsEle\n",
      "\tnChHad\n",
      "\tnNeuHad\n",
      "\tnPhoton\n"
     ]
    }
   ],
   "source": [
    "sel = []\n",
    "for a in active_hlf_features:\n",
    "    for i,f in enumerate(hlf_features):\n",
    "        if a == f:\n",
    "            sel.append(i)\n",
    "\n",
    "print 'Activated HLF:'\n",
    "for n in np.array(hlf_features)[sel]:\n",
    "    print '\\t', n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../data/HLF_ONLY/'\n",
    "TrainSamplesName = ['Wlnu', 'qcd', 'ttbar']\n",
    "BSM_samples = ['Ato4l', 'Zprime', 'Wprime', 'leptoquark']\n",
    "\n",
    "N_train_max = int(2e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiting stat. sample: qcd\n",
      "Wlnu 3505976 701194\n",
      "qcd 2000000 399999\n",
      "ttbar 20000 3999\n"
     ]
    }
   ],
   "source": [
    "trigger_rate = np.array([440., 251., 2.51])\n",
    "fraction = trigger_rate/ np.sum(trigger_rate)\n",
    "\n",
    "raw_sample = {}\n",
    "l = np.zeros(3)\n",
    "for i,n in enumerate(TrainSamplesName):\n",
    "    raw_sample[n] = np.load(data_folder+n+'_lepFilter_13TeV_sample.npy')\n",
    "    l[i] = raw_sample[n].shape[0]\n",
    "    \n",
    "i_min = np.argmin(l/fraction)\n",
    "print 'Limiting stat. sample:', TrainSamplesName[i_min]\n",
    "\n",
    "N_train = min(0.8*l[i_min], N_train_max)\n",
    "\n",
    "x_train_s = {}\n",
    "x_val_s = {}\n",
    "for i,n in enumerate(TrainSamplesName):\n",
    "    N_train_aux = int(N_train * fraction[i]/fraction[i_min])\n",
    "    x_train_s[n] = raw_sample[n][:N_train_aux, sel]\n",
    "    x_val_s[n] = raw_sample[n][N_train_aux : int(N_train_aux*1.2) - 1, sel]\n",
    "    print n, N_train_aux, x_val_s[n].shape[0]\n",
    "    \n",
    "x_train = np.concatenate((x_train_s['Wlnu'], x_train_s['qcd'], x_train_s['ttbar']))\n",
    "x_val = np.concatenate((x_val_s['Wlnu'], x_val_s['qcd'], x_val_s['ttbar']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the VAE declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = x_train.shape[1]\n",
    "latent_dim = 4\n",
    "intermediate_dim = 50\n",
    "act_fun = 'relu'\n",
    "clip_x_to0 = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InverseSquareRootLinearUnit(args, min_value = 5e-3):\n",
    "    return 1. + min_value + K.tf.where(K.tf.greater(args, 0), args, K.tf.divide(args, K.sqrt(1+K.square(args))))\n",
    "\n",
    "def ClippedTanh(x):\n",
    "    return 0.5*(1+0.999*K.tanh(x))\n",
    "\n",
    "def SmashTo0(x):\n",
    "    return 0*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_DNN_input = Input(shape=(original_dim,))\n",
    "hidden_1 = Dense(intermediate_dim, activation=act_fun)(x_DNN_input)\n",
    "hidden_2 = Dense(intermediate_dim, activation=act_fun)(hidden_1)\n",
    "# hidden_3 = Dense(intermediate_dim, activation=act_fun)(hidden_2)\n",
    "\n",
    "L_z_mean = Dense(latent_dim)(hidden_2)\n",
    "\n",
    "L_z_sigma_preActivation = Dense(latent_dim)(hidden_2)\n",
    "L_z_sigma = Lambda(InverseSquareRootLinearUnit)(L_z_sigma_preActivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=1.)\n",
    "    return z_mean + z_sigma * epsilon\n",
    "\n",
    "L_z_latent_DNN = Lambda(sampling)([L_z_mean, L_z_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h1 = Dense(intermediate_dim, activation=act_fun)(L_z_latent_DNN)\n",
    "decoder_h2 = Dense(intermediate_dim, activation=act_fun)(decoder_h1)\n",
    "# decoder_h3 = Dense(intermediate_dim, activation=act_fun)(decoder_h2)\n",
    "L_par1 = Dense(original_dim)(decoder_h2)\n",
    "\n",
    "L_par2_preActivation = Dense(Nf_lognorm + Nf_gauss + Nf_Pgauss + Nf_PDgauss)(decoder_h2)\n",
    "L_par2 = Lambda(InverseSquareRootLinearUnit)(L_par2_preActivation)\n",
    "\n",
    "L_par3_preActivation = Dense(Nf_lognorm)(decoder_h2)\n",
    "L_par3 = Lambda(ClippedTanh)(L_par3_preActivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Prior Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_input = Lambda(SmashTo0)(x_DNN_input)\n",
    "h1_prior = Dense(20, kernel_initializer='zeros', bias_initializer='ones', trainable=False)(fixed_input)\n",
    "# h2_prior = Dense(100, activation=act_fun)(h1_prior)\n",
    "\n",
    "L_prior_mean = Dense(latent_dim, kernel_initializer='zeros', bias_initializer='zeros', trainable=True)(h1_prior)\n",
    "\n",
    "L_prior_sigma_preActivation = Dense(latent_dim, kernel_initializer='zeros', bias_initializer='ones', trainable=True)(h1_prior)\n",
    "L_prior_sigma = Lambda(InverseSquareRootLinearUnit)(L_prior_sigma_preActivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_loss_forVAE(mu, sigma, mu_prior, sigma_prior):\n",
    "    kl_loss = K.tf.multiply(K.square(sigma), K.square(sigma_prior))\n",
    "    kl_loss += K.square(K.tf.divide(mu_prior - mu, sigma_prior))\n",
    "    kl_loss += K.log(K.tf.divide(sigma_prior, sigma)) -1\n",
    "    return K.mean(0.5 * K.sum(kl_loss, axis=-1))\n",
    "\n",
    "def RecoProb_forVAE(x, par1, par2, par3):\n",
    "    N = 0\n",
    "    nll_loss = 0\n",
    "    \n",
    "    #Log-Normal distributed variables\n",
    "    mu = par1[:,:Nf_lognorm]\n",
    "    sigma = par2[:,:Nf_lognorm]\n",
    "    fraction = par3[:,:Nf_lognorm]\n",
    "    x_clipped = K.clip(x[:,:Nf_lognorm], clip_x_to0, 1e8)\n",
    "    single_NLL = K.tf.where(K.less(x[:,:Nf_lognorm], clip_x_to0), \n",
    "                            -K.log(fraction),\n",
    "                                -K.log(1-fraction)\n",
    "                                + K.log(sigma) \n",
    "                                + K.log(x_clipped)\n",
    "                                + 0.5*K.square(K.tf.divide(K.log(x_clipped) - mu, sigma))\n",
    "                           )\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    N += Nf_lognorm\n",
    "    \n",
    "    # Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_gauss]\n",
    "    sigma = par2[:,N:N+Nf_gauss]\n",
    "    norm_x = K.tf.divide(x[:,N:N+Nf_gauss] - mu, sigma)\n",
    "    single_NLL = K.log(sigma) + 0.5*K.square(norm_x)\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    N += Nf_gauss\n",
    "    \n",
    "    # Positive Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_Pgauss]\n",
    "    sigma = par2[:,N:N+Nf_Pgauss]\n",
    "    norm_x = K.tf.divide(x[:,N:N+Nf_Pgauss] - mu, sigma)\n",
    "\n",
    "    sqrt2 = 1.4142135624\n",
    "    aNorm = 1 + 0.5*(1 + K.tf.erf(K.tf.divide(- mu, sigma)/sqrt2))\n",
    "    \n",
    "    single_NLL = K.log(sigma) + 0.5*K.square(norm_x) - K.log(aNorm)\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    N += Nf_Pgauss\n",
    "    \n",
    "    # Positive Discrete Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_PDgauss]\n",
    "    sigma = par2[:,N:N+Nf_PDgauss]\n",
    "    norm_xp = K.tf.divide(x[:,N:N+Nf_PDgauss] + 0.5 - mu, sigma)\n",
    "    norm_xm = K.tf.divide(x[:,N:N+Nf_PDgauss] - 0.5 - mu, sigma)\n",
    "    sqrt2 = 1.4142135624\n",
    "    single_LL = 0.5*(K.tf.erf(norm_xp/sqrt2) - K.tf.erf(norm_xm/sqrt2))\n",
    "    \n",
    "    norm_0 = K.tf.divide(-0.5 - mu, sigma)\n",
    "    aNorm = 1 + 0.5*(1 + K.tf.erf(norm_0/sqrt2))\n",
    "    \n",
    "    single_NLL = -K.log(K.clip(single_LL, 1e-10, 1e40)) -K.log(aNorm)\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    N += Nf_PDgauss\n",
    "    \n",
    "    #Binomial distributed variables\n",
    "    p = 0.5*(1+0.98*K.tanh(par1[:, N: N+Nf_binomial]))\n",
    "    single_NLL = -K.tf.where(K.equal(x[:, N: N+Nf_binomial],1), K.log(p), K.log(1-p))\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    N += Nf_binomial\n",
    "    \n",
    "    #Poisson distributed variables\n",
    "    aux = par1[:, N:]\n",
    "    mu = 1 + K.tf.where(K.tf.greater(aux, 0), aux, K.tf.divide(aux, K.sqrt(1+K.square(aux))))\n",
    "    single_NLL = K.tf.lgamma(x[:, N:]+1) - x[:, N:]*K.log(mu) + mu\n",
    "    nll_loss += K.sum(single_NLL, axis=-1)\n",
    "    \n",
    "    return K.mean(nll_loss)\n",
    "\n",
    "def LossVAE(y_train, NETout):\n",
    "    mu = NETout[:, :latent_dim]\n",
    "    N = latent_dim\n",
    "    \n",
    "    sigma = NETout[:, N: N+latent_dim]\n",
    "    N += latent_dim\n",
    "    \n",
    "    mu_prior = NETout[:, N: N+latent_dim]\n",
    "    N += latent_dim\n",
    "    \n",
    "    sigma_prior = NETout[:, N: N+latent_dim]\n",
    "    N += latent_dim\n",
    "    \n",
    "    par1 = NETout[:, N: N+original_dim]\n",
    "    N += original_dim\n",
    "    \n",
    "    par2 = NETout[:, N: N+Nf_lognorm+Nf_gauss+Nf_Pgauss+Nf_PDgauss]\n",
    "    N += Nf_lognorm+Nf_gauss+Nf_Pgauss+Nf_PDgauss\n",
    "    \n",
    "    par3 = NETout[:, N:N+Nf_lognorm]\n",
    "    \n",
    "    return KL_loss_forVAE(mu, sigma, mu_prior, sigma_prior) + RecoProb_forVAE(y_train[:, :original_dim], par1, par2, par3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecoProb_metric(y_train, NETout):\n",
    "    N = 4*latent_dim\n",
    "    \n",
    "    par1 = NETout[:, N: N+original_dim]\n",
    "    N += original_dim\n",
    "    \n",
    "    par2 = NETout[:, N: N+Nf_lognorm+Nf_gauss+Nf_Pgauss+Nf_PDgauss]\n",
    "    N += Nf_lognorm+Nf_gauss+Nf_Pgauss+Nf_PDgauss\n",
    "    \n",
    "    par3 = NETout[:, N:N+Nf_lognorm]\n",
    "    \n",
    "    return RecoProb_forVAE(y_train[:, :original_dim], par1, par2, par3)\n",
    "\n",
    "def KL_loss_metric(y_train, NETout):\n",
    "    mu = NETout[:, :latent_dim]\n",
    "    sigma = NETout[:, latent_dim: 2*latent_dim]\n",
    "    mu_prior = NETout[:, 2*latent_dim: 3*latent_dim]\n",
    "    sigma_prior = NETout[:, 3*latent_dim: 4*latent_dim]\n",
    "    return KL_loss_forVAE(mu, sigma, mu_prior, sigma_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 23)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           1200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           2550        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            204         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            204         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4)            0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4)            0           dense_3[0][0]                    \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 23)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           250         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 20)           480         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 50)           2550        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            84          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 18)           918         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 11)           561         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            84          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 4)            0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 23)           1173        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 18)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 11)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 68)           0           dense_3[0][0]                    \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,258\n",
      "Trainable params: 9,778\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "global_outputs = KL.concatenate([L_z_mean, L_z_sigma, L_prior_mean, L_prior_sigma, L_par1, L_par2, L_par3], axis=1)\n",
    "\n",
    "vae = Model(inputs=x_DNN_input, outputs=global_outputs)\n",
    "# rms_prop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "vae.compile(optimizer='adam', loss=LossVAE, metrics=[RecoProb_metric, KL_loss_metric])\n",
    "print vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((x_train, np.zeros((x_train.shape[0], 66 - x_train.shape[1]))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5525976 samples, validate on 1105192 samples\n",
      "Epoch 1/100\n",
      "5525976/5525976 [==============================] - 89s 16us/step - loss: 11086.6428 - RecoProb_metric: 11037.6121 - KL_loss_metric: 49.0298 - val_loss: 56.1647 - val_RecoProb_metric: 41.0809 - val_KL_loss_metric: 15.0838\n",
      "Epoch 2/100\n",
      "5525976/5525976 [==============================] - 87s 16us/step - loss: 59.2969 - RecoProb_metric: 43.9906 - KL_loss_metric: 15.3063 - val_loss: 49.2166 - val_RecoProb_metric: 34.3208 - val_KL_loss_metric: 14.8958\n",
      "Epoch 3/100\n",
      "5525976/5525976 [==============================] - 87s 16us/step - loss: 45.8445 - RecoProb_metric: 32.3291 - KL_loss_metric: 13.5154 - val_loss: 41.4006 - val_RecoProb_metric: 28.6734 - val_KL_loss_metric: 12.7272\n",
      "Epoch 4/100\n",
      "5525976/5525976 [==============================] - 86s 16us/step - loss: 38.4413 - RecoProb_metric: 29.3527 - KL_loss_metric: 9.0886 - val_loss: 33.0402 - val_RecoProb_metric: 27.3341 - val_KL_loss_metric: 5.7061\n",
      "Epoch 5/100\n",
      "5525976/5525976 [==============================] - 81s 15us/step - loss: 34.6138 - RecoProb_metric: 28.1866 - KL_loss_metric: 6.4272 - val_loss: 32.9354 - val_RecoProb_metric: 27.4682 - val_KL_loss_metric: 5.4671\n",
      "Epoch 6/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 33.0307 - RecoProb_metric: 27.2169 - KL_loss_metric: 5.8138 - val_loss: 30.7983 - val_RecoProb_metric: 25.2402 - val_KL_loss_metric: 5.5581\n",
      "Epoch 7/100\n",
      "5525976/5525976 [==============================] - 69s 13us/step - loss: 32.3465 - RecoProb_metric: 26.7994 - KL_loss_metric: 5.5471 - val_loss: 30.7948 - val_RecoProb_metric: 25.4138 - val_KL_loss_metric: 5.3810\n",
      "Epoch 8/100\n",
      "5525976/5525976 [==============================] - 75s 14us/step - loss: 31.6449 - RecoProb_metric: 26.0242 - KL_loss_metric: 5.6206 - val_loss: 30.7722 - val_RecoProb_metric: 25.1211 - val_KL_loss_metric: 5.6511\n",
      "Epoch 9/100\n",
      "5525976/5525976 [==============================] - 70s 13us/step - loss: 31.3275 - RecoProb_metric: 25.5627 - KL_loss_metric: 5.7648 - val_loss: 30.1733 - val_RecoProb_metric: 24.5111 - val_KL_loss_metric: 5.6622\n",
      "Epoch 10/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 31.6543 - RecoProb_metric: 25.6102 - KL_loss_metric: 6.0440 - val_loss: 30.2564 - val_RecoProb_metric: 24.1697 - val_KL_loss_metric: 6.0868\n",
      "Epoch 11/100\n",
      "5525976/5525976 [==============================] - 74s 13us/step - loss: 32.1421 - RecoProb_metric: 26.1837 - KL_loss_metric: 5.9584 - val_loss: 30.6822 - val_RecoProb_metric: 25.1576 - val_KL_loss_metric: 5.5247\n",
      "Epoch 12/100\n",
      "5525976/5525976 [==============================] - 76s 14us/step - loss: 31.5516 - RecoProb_metric: 25.4749 - KL_loss_metric: 6.0767 - val_loss: 31.9803 - val_RecoProb_metric: 24.6492 - val_KL_loss_metric: 7.3311\n",
      "Epoch 13/100\n",
      "5525976/5525976 [==============================] - 72s 13us/step - loss: 33.5324 - RecoProb_metric: 27.4666 - KL_loss_metric: 6.0658 - val_loss: 34.6612 - val_RecoProb_metric: 28.7145 - val_KL_loss_metric: 5.9467\n",
      "Epoch 14/100\n",
      "5522800/5525976 [============================>.] - ETA: 0s - loss: 33.5168 - RecoProb_metric: 27.9707 - KL_loss_metric: 5.5461\n",
      "Epoch 00014: reducing learning rate to 0.00010000000475.\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 33.5153 - RecoProb_metric: 27.9693 - KL_loss_metric: 5.5460 - val_loss: 30.5912 - val_RecoProb_metric: 25.2776 - val_KL_loss_metric: 5.3135\n",
      "Epoch 15/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 30.1188 - RecoProb_metric: 24.6453 - KL_loss_metric: 5.4735 - val_loss: 29.7862 - val_RecoProb_metric: 24.2684 - val_KL_loss_metric: 5.5178\n",
      "Epoch 16/100\n",
      "5525976/5525976 [==============================] - 68s 12us/step - loss: 29.6384 - RecoProb_metric: 24.0700 - KL_loss_metric: 5.5683 - val_loss: 29.6025 - val_RecoProb_metric: 23.8888 - val_KL_loss_metric: 5.7138\n",
      "Epoch 17/100\n",
      "5525976/5525976 [==============================] - 73s 13us/step - loss: 29.3493 - RecoProb_metric: 23.7066 - KL_loss_metric: 5.6427 - val_loss: 29.2068 - val_RecoProb_metric: 23.5184 - val_KL_loss_metric: 5.6884\n",
      "Epoch 18/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 29.1617 - RecoProb_metric: 23.4770 - KL_loss_metric: 5.6846 - val_loss: 29.0345 - val_RecoProb_metric: 23.2803 - val_KL_loss_metric: 5.7542\n",
      "Epoch 19/100\n",
      "5525976/5525976 [==============================] - 71s 13us/step - loss: 28.9798 - RecoProb_metric: 23.2696 - KL_loss_metric: 5.7102 - val_loss: 28.8431 - val_RecoProb_metric: 23.1848 - val_KL_loss_metric: 5.6582\n",
      "Epoch 20/100\n",
      "5525976/5525976 [==============================] - 80s 14us/step - loss: 28.9380 - RecoProb_metric: 23.1831 - KL_loss_metric: 5.7550 - val_loss: 28.9339 - val_RecoProb_metric: 23.0026 - val_KL_loss_metric: 5.9313\n",
      "Epoch 21/100\n",
      "5525976/5525976 [==============================] - 77s 14us/step - loss: 28.9286 - RecoProb_metric: 23.1277 - KL_loss_metric: 5.8009 - val_loss: 28.7367 - val_RecoProb_metric: 22.9069 - val_KL_loss_metric: 5.8298\n",
      "Epoch 22/100\n",
      "5525976/5525976 [==============================] - 78s 14us/step - loss: 28.7645 - RecoProb_metric: 22.9553 - KL_loss_metric: 5.8093 - val_loss: 28.7695 - val_RecoProb_metric: 22.7980 - val_KL_loss_metric: 5.9714\n",
      "Epoch 23/100\n",
      "5525976/5525976 [==============================] - 68s 12us/step - loss: 28.7199 - RecoProb_metric: 22.8546 - KL_loss_metric: 5.8652 - val_loss: 28.5623 - val_RecoProb_metric: 22.6677 - val_KL_loss_metric: 5.8946\n",
      "Epoch 24/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 28.6507 - RecoProb_metric: 22.7428 - KL_loss_metric: 5.9078 - val_loss: 28.5714 - val_RecoProb_metric: 22.6169 - val_KL_loss_metric: 5.9545\n",
      "Epoch 25/100\n",
      "5525976/5525976 [==============================] - 69s 13us/step - loss: 28.5705 - RecoProb_metric: 22.6172 - KL_loss_metric: 5.9533 - val_loss: 28.3986 - val_RecoProb_metric: 22.4724 - val_KL_loss_metric: 5.9262\n",
      "Epoch 26/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 28.5200 - RecoProb_metric: 22.5258 - KL_loss_metric: 5.9942 - val_loss: 28.4086 - val_RecoProb_metric: 22.4136 - val_KL_loss_metric: 5.9950\n",
      "Epoch 27/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 28.4477 - RecoProb_metric: 22.3753 - KL_loss_metric: 6.0724 - val_loss: 28.2983 - val_RecoProb_metric: 22.2329 - val_KL_loss_metric: 6.0654\n",
      "Epoch 28/100\n",
      "5525976/5525976 [==============================] - 68s 12us/step - loss: 28.3138 - RecoProb_metric: 22.2386 - KL_loss_metric: 6.0751 - val_loss: 28.1407 - val_RecoProb_metric: 22.0835 - val_KL_loss_metric: 6.0572\n",
      "Epoch 29/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 28.5210 - RecoProb_metric: 22.3627 - KL_loss_metric: 6.1583 - val_loss: 28.3694 - val_RecoProb_metric: 22.2325 - val_KL_loss_metric: 6.1369\n",
      "Epoch 30/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 28.3370 - RecoProb_metric: 22.1455 - KL_loss_metric: 6.1915 - val_loss: 28.8136 - val_RecoProb_metric: 22.5436 - val_KL_loss_metric: 6.2700\n",
      "Epoch 31/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 28.2554 - RecoProb_metric: 22.0127 - KL_loss_metric: 6.2427 - val_loss: 28.8329 - val_RecoProb_metric: 22.6325 - val_KL_loss_metric: 6.2004\n",
      "Epoch 32/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 28.3444 - RecoProb_metric: 22.1287 - KL_loss_metric: 6.2156 - val_loss: 28.0260 - val_RecoProb_metric: 21.7958 - val_KL_loss_metric: 6.2302\n",
      "Epoch 33/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 28.2720 - RecoProb_metric: 21.9913 - KL_loss_metric: 6.2807 - val_loss: 28.5549 - val_RecoProb_metric: 22.2888 - val_KL_loss_metric: 6.2661\n",
      "Epoch 34/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 28.0407 - RecoProb_metric: 21.7217 - KL_loss_metric: 6.3190 - val_loss: 28.0383 - val_RecoProb_metric: 21.7020 - val_KL_loss_metric: 6.3364\n",
      "Epoch 35/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 28.1413 - RecoProb_metric: 21.7643 - KL_loss_metric: 6.3770 - val_loss: 27.9578 - val_RecoProb_metric: 21.5155 - val_KL_loss_metric: 6.4423\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 28.0260 - RecoProb_metric: 21.5801 - KL_loss_metric: 6.4459 - val_loss: 27.7450 - val_RecoProb_metric: 21.2661 - val_KL_loss_metric: 6.4789\n",
      "Epoch 37/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 27.9136 - RecoProb_metric: 21.4360 - KL_loss_metric: 6.4776 - val_loss: 27.9192 - val_RecoProb_metric: 21.3419 - val_KL_loss_metric: 6.5774\n",
      "Epoch 38/100\n",
      "5525976/5525976 [==============================] - 70s 13us/step - loss: 28.0201 - RecoProb_metric: 21.4641 - KL_loss_metric: 6.5560 - val_loss: 27.6040 - val_RecoProb_metric: 21.0617 - val_KL_loss_metric: 6.5423\n",
      "Epoch 39/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 27.9017 - RecoProb_metric: 21.1966 - KL_loss_metric: 6.7051 - val_loss: 27.6504 - val_RecoProb_metric: 20.8999 - val_KL_loss_metric: 6.7504\n",
      "Epoch 40/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 27.8380 - RecoProb_metric: 21.1616 - KL_loss_metric: 6.6764 - val_loss: 27.6171 - val_RecoProb_metric: 20.8896 - val_KL_loss_metric: 6.7275\n",
      "Epoch 41/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.8819 - RecoProb_metric: 21.1516 - KL_loss_metric: 6.7303 - val_loss: 28.0164 - val_RecoProb_metric: 21.2176 - val_KL_loss_metric: 6.7988\n",
      "Epoch 42/100\n",
      "5525976/5525976 [==============================] - 68s 12us/step - loss: 27.6445 - RecoProb_metric: 20.9132 - KL_loss_metric: 6.7313 - val_loss: 27.4826 - val_RecoProb_metric: 20.7520 - val_KL_loss_metric: 6.7307\n",
      "Epoch 43/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 27.5763 - RecoProb_metric: 20.7738 - KL_loss_metric: 6.8025 - val_loss: 27.3295 - val_RecoProb_metric: 20.5325 - val_KL_loss_metric: 6.7970\n",
      "Epoch 44/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.6926 - RecoProb_metric: 20.8680 - KL_loss_metric: 6.8245 - val_loss: 27.4583 - val_RecoProb_metric: 20.6741 - val_KL_loss_metric: 6.7842\n",
      "Epoch 45/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.6260 - RecoProb_metric: 20.7415 - KL_loss_metric: 6.8845 - val_loss: 27.3094 - val_RecoProb_metric: 20.4545 - val_KL_loss_metric: 6.8549\n",
      "Epoch 46/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 27.3957 - RecoProb_metric: 20.5001 - KL_loss_metric: 6.8956 - val_loss: 27.2112 - val_RecoProb_metric: 20.3135 - val_KL_loss_metric: 6.8977\n",
      "Epoch 47/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 27.7557 - RecoProb_metric: 20.7787 - KL_loss_metric: 6.9770 - val_loss: 27.2634 - val_RecoProb_metric: 20.2745 - val_KL_loss_metric: 6.9888\n",
      "Epoch 48/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.2651 - RecoProb_metric: 20.2780 - KL_loss_metric: 6.9871 - val_loss: 27.2488 - val_RecoProb_metric: 20.2156 - val_KL_loss_metric: 7.0332\n",
      "Epoch 49/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.2619 - RecoProb_metric: 20.2515 - KL_loss_metric: 7.0104 - val_loss: 27.0561 - val_RecoProb_metric: 20.0591 - val_KL_loss_metric: 6.9970\n",
      "Epoch 50/100\n",
      "5525976/5525976 [==============================] - 64s 12us/step - loss: 28.9056 - RecoProb_metric: 21.6954 - KL_loss_metric: 7.2102 - val_loss: 27.4421 - val_RecoProb_metric: 20.1979 - val_KL_loss_metric: 7.2442\n",
      "Epoch 51/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.3673 - RecoProb_metric: 20.2757 - KL_loss_metric: 7.0917 - val_loss: 27.2052 - val_RecoProb_metric: 20.1326 - val_KL_loss_metric: 7.0725\n",
      "Epoch 52/100\n",
      "5525976/5525976 [==============================] - 64s 12us/step - loss: 27.1139 - RecoProb_metric: 20.0009 - KL_loss_metric: 7.1129 - val_loss: 26.9601 - val_RecoProb_metric: 19.8624 - val_KL_loss_metric: 7.0977\n",
      "Epoch 53/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 27.3329 - RecoProb_metric: 20.1074 - KL_loss_metric: 7.2255 - val_loss: 27.1322 - val_RecoProb_metric: 19.9529 - val_KL_loss_metric: 7.1793\n",
      "Epoch 54/100\n",
      "5521200/5525976 [============================>.] - ETA: 0s - loss: 27.6730 - RecoProb_metric: 20.4788 - KL_loss_metric: 7.1942\n",
      "Epoch 00054: reducing learning rate to 1.0000000475e-05.\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 27.6742 - RecoProb_metric: 20.4798 - KL_loss_metric: 7.1944 - val_loss: 29.0164 - val_RecoProb_metric: 21.5886 - val_KL_loss_metric: 7.4277\n",
      "Epoch 55/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 27.6387 - RecoProb_metric: 20.3511 - KL_loss_metric: 7.2876 - val_loss: 26.9085 - val_RecoProb_metric: 19.7398 - val_KL_loss_metric: 7.1687\n",
      "Epoch 56/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 26.8614 - RecoProb_metric: 19.6711 - KL_loss_metric: 7.1903 - val_loss: 26.8661 - val_RecoProb_metric: 19.6664 - val_KL_loss_metric: 7.1997\n",
      "Epoch 57/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.8290 - RecoProb_metric: 19.6167 - KL_loss_metric: 7.2123 - val_loss: 26.8431 - val_RecoProb_metric: 19.6244 - val_KL_loss_metric: 7.2187\n",
      "Epoch 58/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.8123 - RecoProb_metric: 19.5908 - KL_loss_metric: 7.2215 - val_loss: 26.8299 - val_RecoProb_metric: 19.6106 - val_KL_loss_metric: 7.2193\n",
      "Epoch 59/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.7999 - RecoProb_metric: 19.5705 - KL_loss_metric: 7.2294 - val_loss: 26.8290 - val_RecoProb_metric: 19.5942 - val_KL_loss_metric: 7.2348\n",
      "Epoch 60/100\n",
      "5523600/5525976 [============================>.] - ETA: 0s - loss: 26.7924 - RecoProb_metric: 19.5508 - KL_loss_metric: 7.2416\n",
      "Epoch 00060: reducing learning rate to 1.00000006569e-06.\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.7925 - RecoProb_metric: 19.5509 - KL_loss_metric: 7.2416 - val_loss: 26.8512 - val_RecoProb_metric: 19.5943 - val_KL_loss_metric: 7.2569\n",
      "Epoch 61/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7721 - RecoProb_metric: 19.5270 - KL_loss_metric: 7.2451 - val_loss: 26.7963 - val_RecoProb_metric: 19.5487 - val_KL_loss_metric: 7.2476\n",
      "Epoch 62/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.7639 - RecoProb_metric: 19.5160 - KL_loss_metric: 7.2479 - val_loss: 26.8388 - val_RecoProb_metric: 19.5939 - val_KL_loss_metric: 7.2449\n",
      "Epoch 63/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.7614 - RecoProb_metric: 19.5156 - KL_loss_metric: 7.2459 - val_loss: 26.7910 - val_RecoProb_metric: 19.5465 - val_KL_loss_metric: 7.2444\n",
      "Epoch 64/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7590 - RecoProb_metric: 19.5132 - KL_loss_metric: 7.2458 - val_loss: 26.7767 - val_RecoProb_metric: 19.5320 - val_KL_loss_metric: 7.2447\n",
      "Epoch 65/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7597 - RecoProb_metric: 19.5123 - KL_loss_metric: 7.2475 - val_loss: 26.8000 - val_RecoProb_metric: 19.5565 - val_KL_loss_metric: 7.2434\n",
      "Epoch 66/100\n",
      "5524400/5525976 [============================>.] - ETA: 0s - loss: 26.7549 - RecoProb_metric: 19.5077 - KL_loss_metric: 7.2471\n",
      "Epoch 00066: reducing learning rate to 1.00000011116e-07.\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 26.7549 - RecoProb_metric: 19.5077 - KL_loss_metric: 7.2472 - val_loss: 26.7932 - val_RecoProb_metric: 19.5426 - val_KL_loss_metric: 7.2506\n",
      "Epoch 67/100\n",
      "5525976/5525976 [==============================] - 66s 12us/step - loss: 26.7524 - RecoProb_metric: 19.5020 - KL_loss_metric: 7.2504 - val_loss: 26.7809 - val_RecoProb_metric: 19.5336 - val_KL_loss_metric: 7.2474\n",
      "Epoch 68/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7543 - RecoProb_metric: 19.5041 - KL_loss_metric: 7.2501 - val_loss: 26.7780 - val_RecoProb_metric: 19.5306 - val_KL_loss_metric: 7.2474\n",
      "Epoch 69/100\n",
      "5525976/5525976 [==============================] - 67s 12us/step - loss: 26.7576 - RecoProb_metric: 19.5076 - KL_loss_metric: 7.2499 - val_loss: 26.7996 - val_RecoProb_metric: 19.5522 - val_KL_loss_metric: 7.2473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "5524800/5525976 [============================>.] - ETA: 0s - loss: 26.7578 - RecoProb_metric: 19.5083 - KL_loss_metric: 7.2495\n",
      "Epoch 00070: reducing learning rate to 1.00000008274e-08.\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7578 - RecoProb_metric: 19.5083 - KL_loss_metric: 7.2495 - val_loss: 26.7846 - val_RecoProb_metric: 19.5368 - val_KL_loss_metric: 7.2477\n",
      "Epoch 71/100\n",
      "5525976/5525976 [==============================] - 65s 12us/step - loss: 26.7520 - RecoProb_metric: 19.5020 - KL_loss_metric: 7.2500 - val_loss: 26.8151 - val_RecoProb_metric: 19.5675 - val_KL_loss_metric: 7.2476\n",
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-26 15:37:03.781929: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "fit_report = vae.fit(x=x_train, y=y_train,\n",
    "        validation_data = (x_val, x_val),\n",
    "        shuffle=True,\n",
    "        epochs=100,\n",
    "        batch_size=400,\n",
    "        callbacks = [\n",
    "                        EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=0.05),\n",
    "                        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, epsilon=0.1, verbose=1),\n",
    "                        TerminateOnNaN()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e93b11d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e9e0e6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "f = plt.figure(figsize=(16,8))\n",
    "style = {'loss':'--', 'RecoProb_metric': 'o', 'KL_loss_metric': '--'}\n",
    "for item in ['loss', 'RecoProb_metric', 'KL_loss_metric']:\n",
    "    plt.plot(np.array(fit_report.history[item][:])[1:], style[item], label=item)\n",
    "    plt.plot(np.array(fit_report.history['val_'+item][:])[1:], style[item], label='val_'+item)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    vae.save('VAE_all-in-one_v3.1.h5')\n",
    "else:\n",
    "    from keras.models import load_model\n",
    "    custom_objects = {\n",
    "        'original_dim': x_train.shape[1],\n",
    "        'latent_dim': latent_dim,\n",
    "        'intermediate_dim': intermediate_dim,\n",
    "        'act_fun': act_fun,\n",
    "        'Nf_lognorm' : Nf_lognorm,\n",
    "        'Nf_gauss' : Nf_gauss,\n",
    "        'Nf_Pgauss' : Nf_Pgauss,\n",
    "        'Nf_PDgauss' : Nf_PDgauss,\n",
    "        'Nf_binomial' : Nf_binomial,\n",
    "        'Nf_poisson' : Nf_poisson,\n",
    "        'LossVAE': LossVAE,\n",
    "        'RecoProb_metric': RecoProb_metric,\n",
    "        'KL_loss_metric': KL_loss_metric    \n",
    "    }\n",
    "    \n",
    "    vae = load_model('VAE_all-in-one_v3.1.h5', custom_objects=custom_objects)\n",
    "    print 'Loaded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prior means and variance array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5934048  -0.19503348 -1.9416506   5.1536703 ]\n",
      "[1.3439608 1.9453639 1.0114549 3.9727116]\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    Prior_Dumper = Model(inputs=x_DNN_input, outputs=[L_prior_mean, L_prior_sigma])\n",
    "    Prior_Dumper.save('prior_all-in-one_v3.1.h5')\n",
    "else:\n",
    "    Prior_Dumper = load_model('prior_all-in-one_v3.1.h5', custom_objects=custom_objects)\n",
    "    \n",
    "aux = Prior_Dumper.predict(np.zeros((1, original_dim)))\n",
    "mu_prior = aux[0][0]\n",
    "sigma_prior = aux[1][0]\n",
    "\n",
    "print mu_prior\n",
    "print sigma_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    encoder = Model(inputs=x_DNN_input, outputs=[L_z_mean, L_z_sigma])\n",
    "    encoder.save('encoder_all-in-one_v3.1.h5')\n",
    "else:\n",
    "    encoder = load_model('encoder_all-in-one_v3.1.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the signal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sig = {}\n",
    "for n in BSM_samples+TrainSamplesName:\n",
    "    s = np.load(data_folder+n+'_lepFilter_13TeV_sample.npy')\n",
    "    x_sig[n] = s[:N_train_max, sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ato4l\n",
      "Wlnu\n",
      "Wprime\n",
      "qcd\n",
      "leptoquark\n",
      "Zprime\n",
      "ttbar\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded = np.array(encoder.predict(x_train))\n",
    "\n",
    "x_sig_encoded = {}\n",
    "for k,v in x_sig.iteritems():\n",
    "    print k\n",
    "    x_sig_encoded[k] = np.array(encoder.predict(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent space mean distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_gaussians(x, mu_vec, sigma_vec):\n",
    "    x = np.atleast_2d(x)\n",
    "    if x.shape[0] <= x.shape[1]:\n",
    "        x = x.T\n",
    "    x_norm = (x - mu_vec)/sigma_vec\n",
    "    single_gaus_val = np.exp(-0.5*np.square(x_norm))/(sigma_vec*np.sqrt(2*np.pi))\n",
    "    return np.sum(single_gaus_val, axis=1)/mu_vec.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histos = []\n",
    "canvases = []\n",
    "binning = [70, -8, 8]\n",
    "\n",
    "SampleName = 'SM'\n",
    "\n",
    "for kk in range(latent_dim):\n",
    "    c = rt.TCanvas('c'+str(kk), 'c'+str(kk), 600, 400)\n",
    "\n",
    "    lower_bound = mu_prior[kk] - 6*sigma_prior[kk]\n",
    "    upper_bound = mu_prior[kk] + 6*sigma_prior[kk]\n",
    "    h = rt.TH1F('hSM{}_{}'.format(SampleName, kk), SampleName, binning[0], lower_bound, upper_bound)\n",
    "    z = x_train_encoded[0, :, kk]\n",
    "    rtnp.fill_hist(h, z, weights=1/float(z.shape[0])*np.ones_like(z))\n",
    "    h.SetStats(0)\n",
    "    h.SetLineColor(rt.kGreen+4-2)\n",
    "    h.SetFillColorAlpha(rt.kGreen+4-2, 0.7)\n",
    "    h.SetFillStyle(3001)\n",
    "    \n",
    "    h.SetTitle('')\n",
    "    h.SetXTitle('Mean of z_{'+str(kk)+'}')\n",
    "    h.SetYTitle('Probability')\n",
    "    \n",
    "    h.Draw('Bar SAME')\n",
    "    histos.append(h)\n",
    "\n",
    "\n",
    "    colors = [1,2,4,rt.kYellow+2,6,7,8,46, 30, 40]\n",
    "    # fill\n",
    "    for i, n in enumerate(x_sig.keys()):\n",
    "        h = rt.TH1F('hBSM{}_{}'.format(i, kk), n, binning[0], lower_bound, upper_bound)\n",
    "        z = x_sig_encoded[n][0, :, kk]\n",
    "        rtnp.fill_hist(h, z, weights=1/float(z.shape[0])*np.ones_like(z))\n",
    "\n",
    "        h.SetStats(0)\n",
    "        h.SetLineColor(colors[i])\n",
    "        h.SetLineWidth(2)\n",
    "        h.Draw('SAME')\n",
    "        histos.append(h)\n",
    "\n",
    "    c.BuildLegend()\n",
    "    c.SetGrid()\n",
    "    c.SetLogy()\n",
    "    c.Draw()\n",
    "    canvases.append(c)\n",
    "    \n",
    "fout = rt.TFile('plots/all-in-one_v3-1_SWAN_meanZ.root', 'RECREATE')\n",
    "for obj in canvases + histos:\n",
    "    obj.Write()\n",
    "\n",
    "fout.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recostruction sum of pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    autoencoder = Model(inputs=x_DNN_input, outputs=[L_par1, L_par2, L_par3])\n",
    "    autoencoder.save('all-in-one_v3-1_SWAN_autoencoder.h5')\n",
    "else:\n",
    "    autoencoder = load_model(SampleName + '_v3-1_SWAN_autoencoder.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_ae_train = autoencoder.predict(x_train)\n",
    "# print pars_ae_train.shape\n",
    "\n",
    "pars_ae_sig = {}\n",
    "for k,v in x_sig.iteritems():\n",
    "    print k\n",
    "    pars_ae_sig[k] = autoencoder.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_possion(x_in, mu_vec):\n",
    "    out = np.zeros_like(x_in)\n",
    "    for i, aux in enumerate(x_in):\n",
    "        out[i] = np.sum(poisson.pmf(aux, mu_vec))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lognorm(x, f, mu_vec, sigma_vec):\n",
    "    x = np.atleast_2d(x)\n",
    "    if x.shape[0] <= x.shape[1]:\n",
    "        x = x.T\n",
    "    \n",
    "    x_clipped = np.clip(x, clip_x_to0, 1e8)\n",
    "    x_norm = (np.log(x_clipped) - mu_vec)/sigma_vec\n",
    "    single_prob = np.where(np.less(x, clip_x_to0),\n",
    "                               f,\n",
    "                               (1-f)*np.exp(-0.5*np.square(x_norm))/(x_clipped*sigma_vec*np.sqrt(2*np.pi))\n",
    "    )\n",
    "    return np.sum(single_prob, axis=1)/mu_vec.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "def sum_of_PDgauss(x, mu, sigma):\n",
    "    x = np.atleast_2d(x)\n",
    "    if x.shape[0] <= x.shape[1]:\n",
    "        x = x.T\n",
    "    \n",
    "    zp = (x + 0.5 - mu)/sigma\n",
    "    zm = (x - 0.5 - mu)/sigma\n",
    "    \n",
    "    norm_0 = (-0.5 - mu)/sigma\n",
    "    \n",
    "    aNorm = 1 + 0.5*(1 + erf(norm_0/np.sqrt(2)))\n",
    "    single_prob = aNorm*0.5*(erf(zp/np.sqrt(2)) - erf(zm/np.sqrt(2)))\n",
    "    return np.sum(single_prob, axis=1)/mu.shape[0]\n",
    "\n",
    "def sum_of_Pgauss(x, mu, sigma):\n",
    "    x = np.atleast_2d(x)\n",
    "    if x.shape[0] <= x.shape[1]:\n",
    "        x = x.T\n",
    "    x_norm = (x - mu_vec)/sigma_vec\n",
    "    norm_0 = - mu/sigma\n",
    "    aNorm = 1 + 0.5*(1 + erf(norm_0/np.sqrt(2)))\n",
    "    \n",
    "    single_prob = aNorm*np.exp(-0.5*np.square(x_norm))/(sigma_vec*np.sqrt(2*np.pi))\n",
    "    return np.sum(single_prob, axis=1)/mu.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax_arr = plt.subplots(1+int(len(active_hlf_features)/3.),3 , figsize=(18,36))\n",
    "\n",
    "for i,hlf_name in enumerate(active_hlf_features):\n",
    "    print hlf_name\n",
    "#     plt.yscale('log', nonposy='clip')\n",
    "    \n",
    "    #Plot distribution of the variable\n",
    "    x_aux = x_train[:, i]\n",
    "    if i < Nf_lognorm:\n",
    "        histo_range = (0, np.percentile(x_aux, 99.))\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=40, range=histo_range)\n",
    "        if np.sum(bin_edges>clip_x_to0) > 0:\n",
    "            i_aux = np.argmin(bin_edges<clip_x_to0)\n",
    "            bin_edges = np.concatenate((np.array([0, clip_x_to0]), bin_edges[i_aux:]))\n",
    "        else:\n",
    "            bin_edges = np.array([0, clip_x_to0])\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=bin_edges, range=histo_range)\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "        bin_width[0] = 1.\n",
    "\n",
    "        mu_vec = pars_ae_train[0][:, i]\n",
    "        sigma_vec = pars_ae_train[1][:, i]\n",
    "        f_vec = pars_ae_train[2][:, i]\n",
    "        spdf_bin_content = np.sum(bin_content)*bin_width*sum_of_lognorm(bincenters, f_vec, mu_vec, sigma_vec)\n",
    "    elif i < Nf_lognorm + Nf_gauss:\n",
    "        histo_range = (np.percentile(x_aux, .1), np.percentile(x_aux, 99.9))\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=40, range=histo_range)\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bincenters[1]-bincenters[0]\n",
    "\n",
    "        mu_vec = pars_ae_train[0][:, i]\n",
    "        sigma_vec = pars_ae_train[1][:, i]\n",
    "        spdf_bin_content = np.sum(bin_content)*bin_width*sum_of_gaussians(bincenters, mu_vec, sigma_vec)\n",
    "    elif i < Nf_lognorm + Nf_gauss + Nf_Pgauss:\n",
    "        histo_range = (np.percentile(x_aux, .1), np.percentile(x_aux, 99.9))\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=40, range=histo_range)\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bincenters[1]-bincenters[0]\n",
    "\n",
    "        mu_vec = pars_ae_train[0][:, i]\n",
    "        sigma_vec = pars_ae_train[1][:, i]\n",
    "        spdf_bin_content = np.sum(bin_content)*bin_width*sum_of_Pgauss(bincenters, mu_vec, sigma_vec)\n",
    "    elif i < Nf_lognorm + Nf_gauss + Nf_Pgauss + Nf_PDgauss:\n",
    "        Nmax = int(np.percentile(x_aux, 99.9))\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=Nmax+1, range=(-0.5, Nmax+0.5))\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bincenters[1]-bincenters[0]\n",
    "\n",
    "        mu_vec = pars_ae_train[0][:, i]\n",
    "        sigma_vec = pars_ae_train[1][:, i]\n",
    "        spdf_bin_content = np.sum(bin_content)*bin_width*sum_of_PDgauss(bincenters, mu_vec, sigma_vec)\n",
    "    elif i < Nf_lognorm + Nf_gauss + Nf_Pgauss + Nf_PDgauss + Nf_binomial:\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=2, range=(np.min(x_aux), np.max(x_aux)))\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bincenters[1]-bincenters[0]\n",
    "        p = 0.5*(1+0.98*np.tanh(pars_ae_train[0][:, i]))\n",
    "\n",
    "        spdf_bin_content = np.zeros_like(bincenters)\n",
    "        spdf_bin_content[np.nonzero(bin_content)[0][1]] = np.sum(p)\n",
    "        spdf_bin_content[np.nonzero(bin_content)[0][0]] = np.sum(1-p)\n",
    "    else:\n",
    "        Nmax = int(np.percentile(x_aux, 99.9))\n",
    "        bin_content, bin_edges = np.histogram(x_aux, bins=Nmax+1, range=(-0.5, Nmax+0.5))\n",
    "        bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "        bin_width = bincenters[1]-bincenters[0]\n",
    "        aux = pars_ae_train[0][:, i]\n",
    "        mu_vec = 1 + np.where(np.greater(aux, 0), aux, np.divide(aux, np.sqrt(1+np.square(aux))))\n",
    "        spdf_bin_content = sum_of_possion(bincenters, mu_vec)\n",
    "\n",
    "\n",
    "    if i < Nf_lognorm:\n",
    "        bin_width[0] = clip_x_to0\n",
    "        \n",
    "    ax_arr[i/3, i%3].errorbar(bincenters, bin_content, xerr=bin_width/2., yerr=np.sqrt(bin_content), fmt='.b', label='input')\n",
    "    ax_arr[i/3, i%3].errorbar(bincenters, spdf_bin_content, xerr=bin_width/2., fmt='.r', label='spdf')\n",
    "    ax_arr[i/3, i%3].grid()\n",
    "    ax_arr[i/3, i%3].set_title(hlf_name + ' - ' + SampleName)        \n",
    "    ax_arr[i/3, i%3].legend(loc='best')\n",
    "    \n",
    "    if hlf_name.startswith('LepIso') or hlf_name.startswith('all'):\n",
    "        ax_arr[i/3, i%3].set_yscale('log')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Statistics with Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import loggamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_KL_loss(mu, sigma):\n",
    "    sp = np.atleast_2d(sigma_prior)\n",
    "    mp = np.atleast_2d(mu_prior)\n",
    "    kl_loss = np.square(sigma)*np.square(sp)\n",
    "    kl_loss += np.square((mp - mu)/sp)\n",
    "    kl_loss += np.log(sp/sigma) -1\n",
    "\n",
    "    return 0.5 * np.sum(kl_loss, axis=-1)\n",
    "\n",
    "def numpy_RecoProb(x, par1, par2, par3):\n",
    "    N = 0\n",
    "    nll_loss = 0\n",
    "    \n",
    "    #Log-Normal distributed variables\n",
    "    mu = par1[:,:Nf_lognorm]\n",
    "    sigma = par2[:,:Nf_lognorm]\n",
    "    fraction = par3[:,:Nf_lognorm]\n",
    "    x_clipped = np.clip(x[:,:Nf_lognorm], clip_x_to0, 1e8)\n",
    "    single_NLL = np.where(np.less(x[:,:Nf_lognorm], clip_x_to0), \n",
    "                            -np.log(fraction),\n",
    "                                -np.log(1-fraction)\n",
    "                                + np.log(sigma) \n",
    "                                + np.log(x_clipped)\n",
    "                                + 0.5*np.square((np.log(x_clipped) - mu) / sigma)\n",
    "                           )\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    N += Nf_lognorm\n",
    "    \n",
    "    # Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_gauss]\n",
    "    sigma = par2[:,N:N+Nf_gauss]\n",
    "    norm_x = (x[:,N:N+Nf_gauss] - mu)/sigma\n",
    "    single_NLL = np.log(sigma) + 0.5*np.square(norm_x)\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    N += Nf_gauss\n",
    "    \n",
    "    # Positive Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_Pgauss]\n",
    "    sigma = par2[:,N:N+Nf_Pgauss]\n",
    "    norm_x = (x[:,N:N+Nf_Pgauss] - mu)/sigma\n",
    "\n",
    "    sqrt2 = 1.4142135624\n",
    "    aNorm = 1 + 0.5*(1 + erf( -mu/(sigma*sqrt2) ))\n",
    "    \n",
    "    single_NLL = np.log(sigma) + 0.5*np.square(norm_x) - np.log(aNorm)\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    N += Nf_Pgauss\n",
    "    \n",
    "    # Positive Discrete Gaussian distributed variables\n",
    "    mu = par1[:,N:N+Nf_PDgauss]\n",
    "    sigma = par2[:,N:N+Nf_PDgauss]\n",
    "    norm_xp = (x[:,N:N+Nf_PDgauss] + 0.5 - mu)/sigma\n",
    "    norm_xm = (x[:,N:N+Nf_PDgauss] - 0.5 - mu)/sigma\n",
    "    sqrt2 = 1.4142135624\n",
    "    single_LL = 0.5*(erf(norm_xp/sqrt2) - erf(norm_xm/sqrt2))\n",
    "    \n",
    "    norm_0 = (-0.5 - mu)/sigma\n",
    "    aNorm = 1 + 0.5*(1 + erf(norm_0/sqrt2))\n",
    "    \n",
    "    single_NLL = -np.log(np.clip(single_LL, 1e-10, 1e40)) -np.log(aNorm)\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    N += Nf_PDgauss\n",
    "    \n",
    "    #Binomial distributed variables\n",
    "    p = 0.5*(1+0.98*np.tanh(par1[:, N: N+Nf_binomial]))\n",
    "    single_NLL = -np.where(np.equal(x[:, N: N+Nf_binomial],1), np.log(p), np.log(1-p))\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    N += Nf_binomial\n",
    "    \n",
    "    #Poisson distributed variables\n",
    "    aux = par1[:, N:]\n",
    "    mu = 1 + np.where(np.greater(aux, 0), aux, aux/np.sqrt(1+np.square(aux)))\n",
    "    single_NLL = loggamma(x[:, N:]+1).real - x[:, N:]*np.log(mu) + mu\n",
    "    nll_loss += np.sum(single_NLL, axis=-1)\n",
    "    \n",
    "    return nll_loss\n",
    "\n",
    "def numpy_loss(x, x_encoded, pars_ae):\n",
    "    mu = x_encoded[0]\n",
    "    sigma = x_encoded[1]    \n",
    "    kl_loss = numpy_KL_loss(mu, sigma)\n",
    "    \n",
    "    nll_loss = numpy_RecoProb(x, pars_ae[0], pars_ae[1], pars_ae[2])\n",
    "    \n",
    "    return [nll_loss + kl_loss, nll_loss, kl_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = numpy_loss(x_train, x_train_encoded, pars_ae_train)\n",
    "\n",
    "loss_sig = {}\n",
    "for n in x_sig.keys():\n",
    "    print n\n",
    "    loss_sig[n] = numpy_loss(x_sig[n], x_sig_encoded[n], pars_ae_sig[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histos = []\n",
    "canvases = []\n",
    "\n",
    "for loss_piece in range(3):\n",
    "    binning = [100, np.min(loss_train[loss_piece]), np.percentile(loss_train[loss_piece], 100*(1-5e-5))]\n",
    "    print binning\n",
    "    c = rt.TCanvas('c'+str(loss_piece), 'c'+str(loss_piece), 800, 600)\n",
    "\n",
    "\n",
    "    h = rt.TH1F('h_loss_SM{}_{}'.format('all-in-one', loss_piece), SampleName, binning[0], binning[1], binning[2])\n",
    "    rtnp.fill_hist(h, loss_train[loss_piece])\n",
    "    h.Scale(1./loss_train[loss_piece].shape[0])\n",
    "\n",
    "    h.SetStats(0)\n",
    "    h.SetLineColor(8)\n",
    "    h.SetFillColorAlpha(8, 0.7)\n",
    "    h.SetFillStyle(3001)\n",
    "    h.Draw('Bar SAME')\n",
    "    histos.append(h)\n",
    "\n",
    "    val_to_cut = np.percentile(loss_train[loss_piece], 100*(1-1e-3))\n",
    "    h.SetTitle(h.GetTitle()+' ({:1.1e})'.format(1e-4))\n",
    "#     print val_to_cut\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    colors = [1,2,4,rt.kYellow+2,6,7,8,46, 30, 40]\n",
    "    # fill\n",
    "    for i, n in enumerate(x_sig.keys()):\n",
    "        z = loss_sig[n][loss_piece]\n",
    "        eff = np.sum(z>val_to_cut)/float(z.shape[0])\n",
    "#         print n, ': {:1.2e}'.format(eff)\n",
    "        h1 = rt.TH1F('h_loss_BSM{}_{}'.format(i, loss_piece), n+' ({:1.1e})'.format(eff), binning[0], binning[1], binning[2])\n",
    "        rtnp.fill_hist(h1, z)\n",
    "        h1.Scale(1./float(z.shape[0]))\n",
    "\n",
    "        h1.SetStats(0)\n",
    "        h1.SetLineColor(colors[i])\n",
    "        h1.SetLineWidth(2)\n",
    "        h1.Draw('SAME')\n",
    "        histos.append(h1)\n",
    "\n",
    "    c.BuildLegend()\n",
    "    h.SetTitle('')\n",
    "    Ytitles = ['Loss tot', 'nll(reco probability)', 'KL divergence']\n",
    "    h.SetXTitle(Ytitles[loss_piece])\n",
    "    h.SetYTitle('Probability')\n",
    "\n",
    "    line = rt.TLine()\n",
    "    line.SetLineColor(rt.kYellow+1)\n",
    "    line.SetLineWidth(3)\n",
    "    line.SetLineStyle(9)\n",
    "    line.DrawLine(val_to_cut,0, val_to_cut,1)\n",
    "\n",
    "    c.SetGrid()\n",
    "    c.SetLogy()\n",
    "    c.Draw()\n",
    "    canvases.append(c)\n",
    "    \n",
    "fout = rt.TFile('plots/'+SampleName+ '_v3-1_SWAN_losses.root', 'RECREATE')\n",
    "for obj in canvases + histos:\n",
    "    obj.Write()\n",
    "\n",
    "fout.Close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "fout = h5py.File('losses/all-in-one_v3-1_array.h5', \"w\")\n",
    "fout.create_dataset('SM_train_mixture', data=np.array(loss_train))\n",
    "\n",
    "for k,v in loss_sig.items():\n",
    "    print k\n",
    "    fout.create_dataset(k, data=np.array(v))\n",
    "    \n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
