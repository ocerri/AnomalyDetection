{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BDTs with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import sys, scipy, pickle\n",
    "from scipy.stats import chi2, poisson\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ROOT as rt\n",
    "import root_numpy as rtnp\n",
    "from utility_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print sklearn.__version__\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlf_features = ['HT', 'METp', 'METo', 'MT', 'nJets', \n",
    "                'bJets', 'allJetMass', 'LepPt', 'LepEta', \n",
    "                'LepIsoCh', 'LepIsoGamma', 'LepIsoNeu', 'LepCharge', \n",
    "                'LepIsEle', 'nMu', 'allMuMass', 'allMuPt', 'nEle', \n",
    "                'allEleMass', 'allElePt', 'nChHad', 'nNeuHad', 'nPhoton']\n",
    "\n",
    "active_hlf_features = ['HT', 'allJetMass',\n",
    "                       'allMuPt', 'allMuMass',\n",
    "                       'allElePt','allEleMass',\n",
    "                       'LepPt', 'LepIsoCh', 'LepIsoGamma', 'LepIsoNeu',\n",
    "                       \n",
    "                       'METp', 'METo',\n",
    "                       \n",
    "                       'MT',\n",
    "                       \n",
    "                       'nMu', 'nJets', 'bJets', 'nEle', \n",
    "                       \n",
    "                       'LepCharge','LepIsEle', \n",
    "                       \n",
    "                       'nChHad', 'nNeuHad']\n",
    "\n",
    "Nf_lognorm = 10\n",
    "Nf_gauss = 2\n",
    "Nf_Pgauss = 1\n",
    "Nf_PDgauss = 4\n",
    "Nf_binomial = 2\n",
    "Nf_poisson = 2\n",
    "\n",
    "sel = []\n",
    "for a in active_hlf_features:\n",
    "    for i,f in enumerate(hlf_features):\n",
    "        if a == f:\n",
    "            sel.append(i)\n",
    "# print 'Activated HLF:'\n",
    "# for n in np.array(hlf_features)[sel]:\n",
    "#     print '\\t', n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/HLF_ONLY/'\n",
    "TrainSamplesName = ['Wlnu', 'qcd', 'Zll', 'ttbar']\n",
    "BSM_samples = ['Ato4l', 'Zprime', 'Wprime', 'leptoquark', 'hToTauTau', 'hChToTauNu']\n",
    "\n",
    "N_train_max = int(6e6)\n",
    "training_split_fraction = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD is limiting, using it for both val and split\n",
      "Limiting stat. sample: qcd\n",
      "Expected 3.45 train\n",
      "Expected 3.45 val\n"
     ]
    }
   ],
   "source": [
    "fraction = np.array([0.592, 0.338, 0.067, 0.003])\n",
    "\n",
    "raw_sample = {}\n",
    "l = np.zeros(4)\n",
    "for i,n in enumerate(TrainSamplesName):\n",
    "    raw_sample[n] = np.load(data_folder+n+'_sample.npy')\n",
    "#     np.random.shuffle(raw_sample[n])\n",
    "    l[i] = raw_sample[n].shape[0]\n",
    "    \n",
    "i_min = np.argmin(l/fraction)\n",
    "if TrainSamplesName[i_min]=='qcd':\n",
    "    print 'QCD is limiting, using it for both val and split'\n",
    "    N_train = min(N_train_max, l[i_min]/fraction[i_min])\n",
    "else:\n",
    "    N_train = min(N_train_max, training_split_fraction*l[i_min]/fraction[i_min])\n",
    "    \n",
    "if N_train < N_train_max:\n",
    "    print 'Limiting stat. sample:', TrainSamplesName[i_min]\n",
    "else:\n",
    "    print 'Sample available satisfying '\n",
    "\n",
    "N_val = N_train*(1-training_split_fraction)/training_split_fraction - 1\n",
    "print 'Expected {:.2f} train'.format(N_train/1.0e6)\n",
    "print 'Expected {:.2f} val'.format(N_val/1.0e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QCD is limiting, using it for both val and split\n",
      "+--------+----------+---------+---------+\n",
      "| Sample | Evts tot |  Train  |   Val   |\n",
      "+--------+----------+---------+---------+\n",
      "|  Wlnu  | 8000082  | 2042566 | 2042565 |\n",
      "|  qcd   | 1166195  | 1166195 | 1166194 |\n",
      "|  Zll   | 1777383  |  231168 |  231168 |\n",
      "| ttbar  | 5001726  |  10350  |  10350  |\n",
      "+--------+----------+---------+---------+\n",
      "Tot training 3.45 M\n",
      "Tot val 3.45 M\n"
     ]
    }
   ],
   "source": [
    "x_train_s = {}\n",
    "x_val_s = {}\n",
    "\n",
    "table = PrettyTable(['Sample', 'Evts tot', 'Train', 'Val'])\n",
    "\n",
    "for i,n in enumerate(TrainSamplesName):\n",
    "    N_train_aux = int(N_train * fraction[i])\n",
    "    x_train_s[n] = raw_sample[n][:N_train_aux, sel]\n",
    "    N_val_aux = int(N_val * fraction[i])\n",
    "    if TrainSamplesName[i_min]=='qcd' and n == 'qcd':\n",
    "        print 'QCD is limiting, using it for both val and split'\n",
    "        np.random.shuffle(raw_sample[n])\n",
    "        x_val_s[n] = raw_sample[n][:N_val_aux, sel]\n",
    "    elif N_train_aux+N_val_aux < raw_sample[n].shape[0]:\n",
    "        x_val_s[n] = raw_sample[n][N_train_aux : N_train_aux+N_val_aux, sel]\n",
    "    else:\n",
    "        print 'Error', n\n",
    "        continue\n",
    "    table.add_row([n, raw_sample[n].shape[0], x_train_s[n].shape[0], x_val_s[n].shape[0]])\n",
    "print table\n",
    "    \n",
    "x_train = np.concatenate((x_train_s['Wlnu'], x_train_s['qcd'], x_train_s['Zll'], x_train_s['ttbar']))\n",
    "x_val = np.concatenate((x_val_s['Wlnu'], x_val_s['qcd'], x_val_s['Zll'], x_val_s['ttbar']))\n",
    "\n",
    "print 'Tot training {:.2f} M'.format(x_train.shape[0]/1.0e6)\n",
    "print 'Tot val {:.2f} M'.format(x_val.shape[0]/1.0e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ato4l 0.652M (10.6)\n",
      "Zprime 0.055M (124.6)\n",
      "Wprime 0.606M (11.4)\n",
      "leptoquark 0.583M (11.8)\n",
      "hToTauTau 0.345M (20.0)\n",
      "hChToTauNu 0.339M (20.4)\n"
     ]
    }
   ],
   "source": [
    "x_sig_train = {}\n",
    "x_sig_val = {}\n",
    "weight_sig = {}\n",
    "for n in BSM_samples:\n",
    "    s = np.load(data_folder+n+'_sample.npy')\n",
    "    N_aux = min(int(N_train_max/training_split_fraction), s.shape[0])\n",
    "    N_train_aux = int(N_aux*training_split_fraction)\n",
    "    N_val_aux = N_aux - N_train_aux\n",
    "    x_sig_train[n] = s[:N_train_aux, sel]\n",
    "    x_sig_val[n] = s[N_train_aux:N_train_aux+N_val_aux, sel]\n",
    "    w = float(x_train.shape[0])/x_sig_train[n].shape[0]\n",
    "    weight_sig[n] = w\n",
    "    print '{} {:.3f}M ({:.1f})'.format(n, s.shape[0]*1.e-6, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_it(n):\n",
    "    bdt_clf[n] = GBC(loss='deviance',\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=150,\n",
    "                     min_samples_leaf=3,\n",
    "                     max_depth=3,\n",
    "#                      max_features=int(x_train.shape[1]*0.5),\n",
    "                     n_iter_no_change=3,\n",
    "                     tol=0.0001,\n",
    "                     validation_fraction=0.2,\n",
    "                     verbose=1\n",
    "                    )\n",
    "\n",
    "    print '\\n\\n------------------ Training', n, '--------------------'\n",
    "    aux_x = np.concatenate(( x_train, x_sig_train[n]))\n",
    "    aux_y = np.concatenate(( np.zeros(x_train.shape[0]), np.ones(x_sig_train[n].shape[0]) ))\n",
    "    w     = np.concatenate(( np.ones(x_train.shape[0]), weight_sig[n]*np.ones(x_sig_train[n].shape[0]) ))\n",
    "\n",
    "    bdt_clf[n].fit(X=aux_x, y=aux_y, sample_weight=w)\n",
    "    joblib.dump(bdt_clf[n], 'Classifier_HLF_v4/Classifier_'+n+'_v4.pkl')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Classifier declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_clf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olmo/programs/miniconda2/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.20.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/olmo/programs/miniconda2/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LogOddsEstimator from version pre-0.18 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/olmo/programs/miniconda2/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator GradientBoostingClassifier from version 0.20.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for n in BSM_samples: \n",
    "    if do_training:\n",
    "        train_it(n)\n",
    "    else:\n",
    "        filename = ('Classifier_HLF_v4/Classifier_'+n+'_v4.pkl')\n",
    "        bdt_clf[n] = joblib.load(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eff_SM = 5.38e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve(p_BSM, p_SM, eval_q_SM):\n",
    "    eval_p = np.percentile(1-p_SM, q=100*eval_q_SM)\n",
    "    \n",
    "    out = (1-p_BSM) < np.atleast_2d(eval_p).T\n",
    "    out = np.sum(out, axis=1)\n",
    "    q_BSM = out/float(p_BSM.shape[0])\n",
    "    \n",
    "    AUC = np.trapz(q_BSM, eval_q_SM)\n",
    "    \n",
    "    return q_BSM, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax_arr = plt.subplots(3,2 , figsize=(18,18))\n",
    "\n",
    "f_ROC, ax_arr_ROC = plt.subplots(1,1, figsize=(10,10))\n",
    "\n",
    "for i,n in enumerate(BSM_samples):\n",
    "    p_SM = bdt_clf[n].predict_proba(x_val)[:,1]\n",
    "    p_BSM = bdt_clf[n].predict_proba(x_sig_val[n])[:,1]\n",
    "    \n",
    "    # print ROC curve\n",
    "    q_SM = np.logspace(base=10, start=-7, stop=0, num=100)\n",
    "    q_BSM, roc_auc = ROC_curve(p_BSM, p_SM, q_SM)\n",
    "    dic2save = {'eff_BSM':q_BSM, 'eff_SM':q_SM, 'roc_auc':roc_auc}\n",
    "    fileout = open('Classifier_HLF_v4/ROC_dict_{}.pkl'.format(n), 'w')\n",
    "    pickle.dump(file=fileout, obj=dic2save)\n",
    "    fileout.close()\n",
    "    ax_arr_ROC.plot(q_SM, q_BSM, label='{} (area = {:0.2f})'.format(n, roc_auc))\n",
    "    \n",
    "    \n",
    "\n",
    "    q = np.percentile(p_SM, 100*(1-Eff_SM))\n",
    "    eff_BSM = float(np.sum(p_BSM>q))/x_sig_val[n].shape[0]\n",
    "\n",
    "    print '{}: {:1.2e}'.format(n, eff_BSM)\n",
    "    \n",
    "    bins = np.logspace(base=10, start=-4, stop=0, num=50)\n",
    "    if n=='Wprime':\n",
    "        bins = np.logspace(base=10, start=-2, stop=0, num=50)\n",
    "    ax_arr[i/2,i%2].hist(1-p_SM, bins=bins, alpha = 0.5, label='SMMix')\n",
    "    ax_arr[i/2,i%2].hist(1-p_BSM, bins=bins, alpha=0.5, label=n)\n",
    "    ax_arr[i/2,i%2].plot([1-q,1-q], [0,1e6], '--r', label='cut')\n",
    "\n",
    "    ax_arr[i/2,i%2].set_title('{} classifier, eff {:1.2e}'.format(n, eff_BSM))\n",
    "    ax_arr[i/2,i%2].legend(loc='best')\n",
    "    ax_arr[i/2,i%2].set_ylabel('Events')\n",
    "    ax_arr[i/2,i%2].set_xlabel('Probability SM predicted')\n",
    "    ax_arr[i/2,i%2].set_yscale('log')\n",
    "    ax_arr[i/2,i%2].set_xscale('log')\n",
    "    \n",
    "ax_arr_ROC.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax_arr_ROC.plot([Eff_SM, Eff_SM], [1e-6, 1.05], color='red', lw=2, linestyle='--', label='1000 SM evts/month')\n",
    "ax_arr_ROC.set_xlim([1e-6, 1.0])\n",
    "ax_arr_ROC.set_ylim([1e-6, 1.05])\n",
    "ax_arr_ROC.set_xlabel('SM efficiency')\n",
    "ax_arr_ROC.set_ylabel('BSM efficiency')\n",
    "ax_arr_ROC.set_title('ROC supervised training')\n",
    "ax_arr_ROC.legend(loc=\"lower right\")\n",
    "ax_arr_ROC.set_yscale('log')\n",
    "ax_arr_ROC.set_xscale('log')\n",
    "ax_arr_ROC.grid()\n",
    "f_ROC.savefig('Classifier_HLF_v4/ROC_clf.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
